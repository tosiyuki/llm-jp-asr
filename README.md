# llm-jp-asr
Whisperã®ãƒ‡ã‚³ãƒ¼ãƒ€ã‚’[llm-jp/llm-jp-1.3b-v1.0](https://huggingface.co/llm-jp/llm-jp-1.3b-v1.0)ã«ç½®ãæ›ãˆãŸéŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚

[ã€éŸ³å£°èªè­˜ã‚³ãƒ³ãƒšã€‘æ–‡å­¦ä½œå“ã®éŸ³å£°ã‚’ æ–‡å­—èµ·ã“ã—ã—ã‚ˆã†ï¼ğŸ“˜ğŸ§](https://competition.nishika.com/competitions/audio_book_transcription/summary)ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã«ä½œæˆã—ãŸã‚³ãƒ¼ãƒ‰ã§ã™ã®ã§ã€å¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¼ãƒ‰ã¯æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‚

ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ã¯[Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words, Nozawa, K., et al.(2024).](https://www.arxiv.org/abs/2408.08027)ã‚’å‚è€ƒã«éŸ³å£°ç‰¹å¾´é‡ã‚’LLMã®å…¥åŠ›ã¨ã—ã¦ä½¿ãˆã‚‹ã‚ˆã†ã«å°„å½±ã—ã¦ã„ã¾ã™ã€‚

<img src="imgs/img1.png" width="500">

## ç’°å¢ƒæ§‹ç¯‰
```
poetry install
```

## å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ä»¥ä¸‹ã®ã‚ˆã†ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚

```:å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«
audio,sentence
éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®Path1,æ­£è§£ãƒ©ãƒ™ãƒ«1
éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®Path2,æ­£è§£ãƒ©ãƒ™ãƒ«2
ãƒ»
ãƒ»
ãƒ»
```

> [!TIP]
> ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å¤‰æ›´ã—ãŸã„å ´åˆã€[llm_asr/train/dataset.py](https://github.com/tosiyuki/llm-jp-asr/blob/main/llm_asr/train/dataset.py)ã®LazySupervisedDatasetã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚

## å®Ÿè¡Œ
### å­¦ç¿’
```
poetry run python train.py
```

> [!TIP]
> èµ·å‹•å¼•æ•°ã«ã¤ã„ã¦ã¯[llm_asr/train/arguments_dataclass.py](https://github.com/tosiyuki/llm-jp-asr/blob/main/llm_asr/train/arguments_dataclass.py)ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚

### æ¨è«–
```
poetry run python inference.py
```


